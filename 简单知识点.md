## 进程和线程的区别

```java
1、进程是资源分配的基本单位，线程是 CPU 调度的基本单位，可以把进程当作一个平台，线程是该平台真正工作的员工，线程会共享进程中的资源（堆、方法区、打开的文件、虚拟地址页等），不过线程（员工）也有私有的资源（栈、程序计数器）
2、一个进程内部含有一个或多个线程，至少存在一个线程。
3、由于一个 CPU 只有一个 MMU，CPU 核心共用这个 MMU，所以一个 CPU 只能调度一个进程，多个 CPU 核心可以同时执行该进程中的多个线程（不过后续好像每个 CPU 核心都有一个 MMU，所以一个 CPU 核心可以调度一个进程）
4、进程上下文切换比线程上下文切换还要更加消耗资源，因为（同个）进程的线程上下文切换，它的虚拟地址页、CPU cache 等都是可以继续使用的，只需要切换线程私有的资源即可，而进程上下文切换或者不同进程的线程上下文切换，那么需要保存旧进程的虚拟地址页和其他资源，然后加载新进程的虚拟地址页和其他资源，同时 CPU cache 中的数据全部无效。
```



## Mysql 和 redis 的区别

```java
1、Mysql 是一个关系型数据库，各个实体以及实体之间都存在联系，同时将相同实体的数据以表的形式存储起来；redis 是一个非关系型数据库，数据之间不存在任何的联系，数据是以 key-value 的形式存储的
2、Mysql 的数据持久化在磁盘上，数据读取默认是在 buffer pool 中的，如果不命中，那么需要磁盘 IO；redis 是内存数据库，数据都存储在内存中，读写都是在内存中进行，但是为了防止宕机所以会定时将数据进行持久化。
3、Mysql 的事务支持回滚；redis 的事务不支持回滚（为了更加简单高效）。
```



## Mysql 一次 select 的过程

```java
1、服务器和数据库建立连接
	服务器和数据库之间使用的是 TCP 连接，验证完用户名和密码都，每一条 connection 都是一条 TCP 连接，所以为了防止频繁的创建和销毁，因此使用长连接的方式，同时跟线程池一样，使用一个数据库连接池来管理和复用 TCP 连接。
	这个 TCP 连接设置为 半双工的，即同一时间只能有一方发送数据。
2、查询缓存
	数据库内存会维护一个 buffer 用于查询，底层应该是一个类似 HashTable 的数据结构，select 语句为 key，查询出来的数据为 value。它会先判断 select 语句是否存在缓存，如果缓存命中，那么直接获取返回，否则进入 sql 解析。
	这个缓存在多写的情况下没有什么作用，一旦数据被修改，那么对应的缓存也都全部无效，这样在多写的情况下基本不会存在缓存命中，但又需要花费资源去维护，比较鸡肋。好像 Mysql 8.0 删除了这个缓存
3、sql 解析
	1）词法解析，将 sql 语句分解为一个个的 token，判断关键字是否缺失、关键字的位置是否正确等。
	2）语法解析：将词法解析得到的 token 生成一棵语法树，将对应关键字后面的参数存储到不同的数据结构中，比如 select 后面是查询的字段，那么存储到用于存储查询字段的 List 中，from 后面是表名，那么将后面的参数存储到 表名的 List 中。
	3）预处理：根据语法解析得到的语法树来判断其中的字段、表名是否存在。
4、查询优化器
	根据语法树来生成合适的执行计划，比如如果存在多个索引，那么使用哪个索引更好（查询优化器选择的索引不一定的最优的，根据实际情况可以使用 force index() 来强制指定使用哪一个索引）
5、执行器 执行 执行计划
	执行器拿到执行计划，调用存储引擎层的接口获取数据，存储引擎层根据对应的查询条件去查询索引树，如果需要回表那么就进行回表，这里会通过索引下推来减少回表次数，然后将完整的数据返回给 Server 层。Server 收到数据后，根据其他的查询条件进行过滤，如果满足条件那么存储到结果集中，然后调用接口获取下一条语句。
	当全部查询完毕，可以根据 group by 之类的其他语法进行处理。
```





## 用户态和内核态

```java
内核态 和 用户态 是 CPU 的两个状态，而不是操作系统的两个状态
CPU 指令分为特权指令 和 非特权指令，特权指令在内核态状态下执行，非特权指令在用户态状态下执行
CPU 这两种状态的区别在于它们能够访问的资源不同

操作系统将物理内存分为两部分，比如 4GB，那么低位的 1GB 是内核空间，高位的 3GB 是用户空间
这个所谓的内核空间是指 CPU 处于内核态模式时才能访问的地址。

因为操作系统最主要的是稳定性，内核空间用来存储重要的计算机资源，用户空间用来运行用户程序
内核空间对外开放了访问接口，称作系统调用，用户空间可以通过系统调用去按照这个规则来访问内核空间的数据，这类似 Java 类的封装，一个类对外开放接口，其他的类只能调用这个类对外开放的接口来访问和修改数据，能够访问和修改什么数据辑由该 Java 类决定，其他 Java 类无法修改这个逻辑。不同的是，操作系统没有 Java 的反射，所以能够更加保证稳定性。


CPU 有 3 种情况会从用户态切换到内核态：
1、系统调用：
	mmap()、sendfile()、read()、write()、fork()、alloac()
2、中断
3、异常
```



## 设计模式

```java
单例模式：
	没什么好讲的
	
工厂模式：
	Spring IOC，简单工厂模式 + 八个后置处理器
	
代理模式：
	JDK 动态代理 和 CGLIB 动态代理（Spring AOP 跟单纯的冬天代理的区别，即有什么是单纯的动态代理无法做到的）
	
适配器模式：
	FutureTask（Runnable 适配为 Callable，后续出现一种新的任务类型直接实现一个适配器即可，不需要修改代码）、Spring MVC 获取处理 handler 类型的适配器 HandlerAdapter（内部通过 support() 来判断是否适配该 handler 类型，后续出现新的 handler 也只需要实现一个新的适配器即可，不需要修改代码）、Spring AOP 找通知类型 advice 所属的方法拦截器（通过适配器的 support() 判断是否能够处理 advice，如果可以，那么封装对应的方法拦截器）
	
观察者模式：
	Spring 的事件监听机制
```



## 进程的通信方式

```java
1、匿名管道
	以内存的形式存在
	Linux 命令中的 |，表示将前一个命令的输出用于后一个命令的输入。
	只能用于父子进程
	是内核空间的一段缓存，大小有限
	只能传输字节流数据
	用完即毁
    单向通信，同步阻塞 BIO
2、命名管道
	以文件形式存在
	通信是通过网络连接的方式
	用于不同主机或者同个主机的任意两个进程
	通信的数据也是存在于内核空间的一段缓存中，大小有限
	命名管道存在两种数据格式：字节流模式和消息模式。假设发送方写入 10B，如果是字节流模式，接收方可以一次读取 10B 或者 1B 的；如果是消息模式，那么接收方必须将 10B 全部读取，如果读取其中一部分会读取失败。
	命名管道可以设置同步阻塞和同步非阻塞、单向通信和双向通信，但是它是半双工的，同一时间只能有一个进程能够发送数据（跟 socket 的主要区别在于此，socket 是全双工的）
3、消息队列
	消息队列是内核空间的一段链表，数据是以数据块的形式（类似于 Node）
	每个数据块只能存储一种相同类型的数据，不同的数据块可以存储不同类型的数据
	数据块的大小是有限的
	消息队列就跟邮箱一样，它不依赖于任何一个进程，即使不存在进程通信，这个邮箱也是存在的，并且每个进程读写都是指定哪个邮箱，而不会指定哪个进程，比如 send(A, message) 表示向 邮箱 A 发送数据，recv(A, message) 表示从 邮箱 A 读取数据。
    消息队列用于异步通信
4、共享内存
	管道和消息队列 数据都是存储在内核缓存中的，那么每次读写都需要进行 CPU 上下文切换 和 用户空间和内核空间的拷贝，效率低。
	共享内存是进程各自拿出一部分虚拟页，映射到同一个用户空间的物理地址上（当然某些情况下是可以映射到内核空间的，比如 mmap()），这样它们可以将数据放到共享内存上，别的存在映射的进程可以直接从这个共享内存上获取数据，不需要经过内核空间。
	共享内存支持多个进程，当关闭时由最后一个进程进行关闭。
6、信号量
	共享内存多个进程的读写会存在数据混乱的问题，因此需要一种机制 -- 信号量 来限制进程的数据访问顺序。
	信号量定义了两个操作：P 和 V，分别表示获取资源 和 释放资源。
	当一个进程执行 P 操作获取资源，如果所剩资源为 0，那么该进程阻塞，直到别的进程释放资源。
	sync 锁 和 lock 就是在资源只有 1 的情况下的信号量
5、信号
	信号是异步通信。
	通过发送信号来告知进程执行某个事件，比如 
	kill -15 指令会发送信号告知进程终止执行，不过它是否终止由它自己判断；
	kill -9 指令则是让进程强制终止执行；
	当子进程执行完成退出时，会给父进程发送信号，让父进程来处理剩下的 PCB（如果父进程不处理，那么会导致子进程变成僵尸进程，占用 PID）
6、socket
	socket 用于两个不同主机之间的进程通信。它是对 TCP/IP 的一层封装，让应用层能够更加方便的进行数据传输。
	一次完整的网络 IO 如下：
		1）DMA 将网卡设备缓冲区的数据拷贝到内核空间的缓冲区
		2）CPU 将内核空间缓冲区的数据拷贝到用户空间的缓冲区
		3）CPU 将用户空间缓冲区的数据拷贝到内核空间的 socket 缓冲区
		4）DMA 将内核空间的 socket 缓冲区数据拷贝到网卡设备的缓冲区进行发送
	这里需要两次 CPU copy 和 四次 CPU 上下文切换（内核态和用户态的切换），因此出现了零拷贝技术
	
	1、mmap()，利用 mmap() 来代替 read()
		1）DMA 将网卡设备的数据拷贝到内核空间的缓冲区
		2）操作系统将内核空间的这部分空间跟用户空间建立映射，省去了一次 CPU copy
		3）CPU 将内核空间缓冲区中的数据拷贝到 socket 缓冲区
		4）DMA 将 socket 缓冲区中的数据拷贝到网卡设备的缓冲区
	这里需要一次 CPU copy 和 四次 CPU 上下文切换
	2、sendfile() 一个函数代替 read() 和 write()
		1）DMA 将网卡设备的数据拷贝到内核空间的缓冲区
		2）CPU 将内核空间的缓冲区直接拷贝到 socket 缓冲区
		3）DMA 将 socket 缓冲区的数据拷贝到网卡设备的缓冲区
	这里需要一次 CPU copy 和 两次 CPU 上下文切换
	3、sendfile() + DMA 辅助
	这里需要零次 CPU copy 和 两次 CPU 上下文切换
	
```





## 进程的调度算法

[非常详细的进程调度算法（里面包含了其他操作系统知识）](https://www.yuque.com/u90713/itme1v/eao1gz?language=en-us)

```
1、先来先服务算法
2、短作业优先算法（非抢占）
3、最短完成时间算法（抢占）
4、高响应比算法
5、时间片轮转算法
6、多级反馈队列调度算法
7、CFS 算法
```

```java
1、先来先服务算法（非抢占）
	先来任务先进行调度
	问题在于一个 100s 的长任务先来，一个 1s 的短任务先来，那么这个 1s 的短任务需要等待 100s 的时间，导致平均等待时间增长
	
2、短作业优先算法（非抢占）
	无论谁先来后到，执行时间短的任务先执行完成。
	问题在于如果短任务过多，可能会导致长任务饥饿
	
3、最短完成时间优先（抢占式）
	是在短作业优先的基础上进行的修改
	当一个新的任务到来时，会将所有任务和新来的任务进行比较，哪个能够在最短的时间内完成，那么就调度哪个任务，所以原先执行的任务的时间片可能会被新的任务或其他任务抢占。
	比如一个 100s 的长任务只剩下 1s，来了一个 10s 的短任务，那么仍然会继续执行长任务
	
4、高响应比优先（非抢占）
	满足短任务优先但又不会导致长任务饥饿
	①、当等待时间相同（短任务和长任务同时等待），短任务优先
	②、当任务执行完成的时间相同时（两个相同的短任务），等待时间长的优先（相当于先来先服务）
	③、长作业的优先级会随着等待时间的增加而提高，因此在等待一段时间后能够得到调度，不会饥饿。
	
5、时间片轮转算法
	不考虑优先级，按照先来先服务调度的思想，每个进程分配一个时间片
	如果进程在一个时间片内能够完成任务，那么出队，不会强制等到时间片结束，继续调用别的进程
	如果进程在一个时间片内没有完成任务，那么入队到队尾，等待下一次调度
	
	问题在于时间片的大小难以控制，时间片太短会导致进程上下文的频繁切换，时间片太长会导致后面调度的进程等待太长时间，对于用户交互来说不友好

6、多级反馈队列调度算法
	设置 n 个队列，最上面的队列优先级最高的，下面的队列优先级逐步降低，但是越往下分配的队列中任务分配的时间片也越长。
	①、新来的任务进入到最上面的队列中
	②、CPU 最先调度上层队列的任务
	③、如果一个任务在分配的时间片中没有执行完成，那么降级到下一个队列中
	④、如果一个进程在调度过程中主动放弃 CPU 时间片，那么不进行降级处理
		④的意图很简单：如果一个进程是一个跟用户交互型的任务，存在大量的 IO 操作，那么它会在时间片用完前主动放弃 CPU，这样的话不希望对它进行降级，让它能够继续被调度。
		不过 ④ 存在问题：如果队列中存在大量的交互型任务，那么会导致下层队列任务的饥饿，同时恶意程序可能会利用这个问题来霸占 CPU，因此出现了 ⑤ 和 重写的 ④
	⑤、经过一段时间 S 后，将所有队列中的任务都重新加入到最上层队列中重新调度（防止饥饿）
	重写④、一个进程在某个队列待的时间超过了设置的值，那么强行降级到下一个队列中（即不允许一个进程待太长时间）。

7、CFS 调度算法
	这个算法是 Linux 正在使用的算法，完全公平调度算法。
	它定义了一个新的模型，给每个进程分配一个 vruntime(虚拟运行时间)，当一个进程得到调度，那么它的 vruntime 会增加，即如果一个进程没有得到调度，那么它的 vruntime 会比其他的进程要小，那么 CPU 就会去调度它。CPU 每次调度的都是 vruntime 最小的一个。
	为了让优先级高的进程有更多的时间片，所以优先级高的进程的 vruntime 的增长速率比其他进程慢
	同时存在以下概念：
	1）调度周期：将所有的进程调度一遍所需要的时间
	2）进程权重：表示进程的优先级
    一个调度周期内进程所需要分配的时间片：调度周期 * 进程权重 / 所有进程权重之和
		比如调度周期为 30s，进程 A 的权重为 1，进程 B 的权重为 2，那么进程 A 分配的时间片为 10s，进程 B 分配的时间片为 20s
	vruntime = 进程实际的运行时间 * 1024 / 进程权重
	在理想情况下，假设所有的进程在一个调度周期内的时间片都已经执行完毕，那么进程实际的运行时间 = 一个调度周期内进程需要分配的时间片，以上两式组合，有
	vruntime = 调度周期 * 1024 / 所有进程权重之和。
	可以看到，vruntime 的增长跟单个进程权重无关，如果所有进程在一个调度周期内都分配到了应得的时间片，那么它们最终的 vruntime 是相同的。
	不过对于进程权重大的进程，它在一个调度周期能需要分配更多的时间片，所以它的进程实际运行时间会比别的进程多，在分配了相同时间片的情况下，优先级高的进程它的 vruntime 会比其他进程要小，所以 CPU 会去调度这个进程，但是如果都得到了应得的时间片，那么它们最终的 vruntime 都是相同的。
	CFS 的设计思想：个人感觉是在 时间片轮转算法 上进行改进，时间片轮转算法是在某种意义上的公平，比如分蛋糕，人有高矮胖瘦，食量也不一样，时间片轮转算法就是每个人都分得相同份量的蛋糕，但是对于实际上而言，瘦的和胖的它们的满足感和饱腹感是不一样的，瘦的可能满足，但胖的不一定会满足。而 CFS 则不是按照份量，而是想让所有人都能够达到相同程度的满足感和饱腹感来分配蛋糕的份量，所以对于胖的会分配得多，但是最终它们的满足感和饱腹感是一样的。
	Linux 实现 CFS 底层使用的是红黑树，按照进程的 vruntime 进行排序，每次 O(logn) 找到最左边的节点进行调度即可。
```



## OS 进程（线程）和 Java 线程的状态转换

```java
1、OS 进程（线程）的五种状态
1）初始化：进程刚创建，正在分配资源
2）运行状态：进程正在被 CPU 调度
3）就绪状态：进程等待被 CPU 调度
4）阻塞状态：进程遇到 IO 事件、信号量 P 操作等待获取资源等阻塞操作，等待阻塞事件完成后会进入到就绪状态
5）终止状态：进程正常执行完毕退出 或者 异常终止 或者 被 kill 指令强制终止

2、Java 线程的六种状态
1）NEW：线程刚创建，还没有调用 start()
2）RUNNABLE：线程调用了 start()，正在被 CPU 调度或者等待被 CPU 调度
3）WAITING：无限期的等待，比如 wait()、join()、park() 等函数
4）TIMED_WAITING：超时等待，比如 wait(1000)、sleep(1000)、join(1000)、parkNanos()，这种都是限时等待，超过时间后会自动唤醒，不过如果 wait(1000) 醒来后仍然会进入到 EntryList 队列中等待获取锁，其他的情况则是进入到 RUNNABLE 状态，等待 CPU 调度
5）BLOCKED：Java 线程只有在获取 sync 锁才会陷入阻塞状态（即使是 IO 事件也是处于 RUNNABLE）
6）TEMPRXXX：线程正常退出或者异常退出。
    

线程让出 CPU 的函数：
1）wait()
2）sleep()
3）join()
4）park()
5）yield()：注意 yield 的线程是可能再次抢到 CPU 的，基本不会使用该方法
```





## Linux 的线程是什么东西？

```java
Linux 本质上并没有线程的概念，即它没有为线程单独定义一个数据结构，它是把线程当作一个标准的进程来调用的，即 CPU 调度的仍然是进程，所谓的同个进程中的多个线程是能够共享这个大进程的某些资源的小进程，每个线程都有一个 task_struct 结构，称作 “轻量级进程”
	（task_struct：PCB 的一种实现）
相当于说我们创建一个进程，它是大进程，是资源分配的基本单位，单单只是用来存储资源的，而内部默认情况下有一个小进程，即我们自己说的线程，它具有一个 task_struct 结构，存储的是该小进程的信息，这个 task_struct 存储了该小进程的调用栈、优先级、进程的状态等，而它能够访问到外部大进程的资源。
如果存在多个小进程（多个线程），那么它们都有各自的私有资源，但能够共享外部的资源，即外部的大进程实际上不算作一个进程，单单只是一个资源分配的平台而已，真正 CPU 调度的是内部的这些小进程。


Linux 线程 和 fork() 子进程的区别：
Linux 线程是共享大进程的资源，是共享，它们操作的是同一份资源；fork() 出来的子进程则是拷贝父进程持有的资源，它操作的是父进程资源的副本。


Linux 的进程上下文切换和线程上下文切换：
1）进程上下文切换是切换外部大进程的资源，比如要调用大进程 2 中的某个线程，那么需要从大进程 1 切换到大进程 2，将大进程 1 的数据段、代码段、虚拟页之类的保存起来，然后将大进程 2 的数据段、代码段、虚拟页之类的进行刷新，然后再调用大进程 2 中的小进程（线程）。
	需要保存和刷新的资源比较大，同时 CPU cache 中是 大进程 1 的资源，对于大进程 2 来说是无效的，需要重新刷新
	一旦发生进程上下文切换，实际上必定也会跟随着线程上下文切换，因为进程上下文切换实际上是从大进程 1 的某个小进程切换到调用大进程 2 的某个小进程。
2）线程上下文切换是切换的内部的小进程，数据段、代码段、虚拟页都不需要进行刷新，只需要切换线程私有的 栈、线程ID（进程 PID）、进程的状态、PC 寄存器
```

<img src="https://pic.leetcode-cn.com/1609559719-sgtnAI-image.png" style="zoom:70%;" />



## cookie 和 session

```java
cookie 和 session 都是用来解决 HTTP 无状态的问题。
HTTP 协议不会去记住上一次请求的用户的信息，因此如果只有 HTTP 协议的话，那么用户每次请求都需要携带用户信息或者进行登录。

1、cookie 机制：
cookie 机制是由浏览器保存用户信息的。
当用户第一次访问的时候，服务器发现请求头没有携带 cookie 信息，那么会让浏览器跳转到登录页面，用户登录，服务器会生成一个 cookie，内部存储用户的信息，然后通过 set-cookie 将 cookie 返回给浏览器保存，下次浏览器访问的时候带上这个 cookie，那么服务器就无需让用户再次登录。

cookie 的类型：
1）cookie 如果没有设置时间，那么它的生命周期为浏览器会话期间，存储在浏览器的内存中，一旦关闭浏览器，那么 cookie 也会销毁，那么下次访问用户仍然需要登录，这种 cookie 叫做 session cookie（会话 cookie）
2）cookie 如果设置了过期时间，那么它的生命周期为这个过期时间，浏览器会将它持久化到磁盘上，即使浏览器关闭了，这个 cookie 仍然存在，这种 cookie 叫做 持久化 cookie

2、session 机制：
session 机制是由服务器保存用户信息。
当用户第一次访问的时候，服务器会为该用户生成一个 session 数据结构，然后保存在自己的内存中，同时为了能够标识哪个用户对应哪个 session，每个 session 还会存在一个唯一标识 JSESSIONID，而用户访问的时候，需要知道它对应着哪个 session，需要将 JSESSIONID 保存在浏览器上，相当于身份卡，每次访问携带上这个 JSESSIONID 即可，这样服务器就可以根据 JSESSIONID 来获取对应的 session。
而浏览器的 JSESSIONID 的存储一般是借助 cookie 机制来实现的，保存在 cookie 中，每次访问通过携带 cookie 来携带 JESSIONID。

3、cookie 机制 和 session 机制的区别：
1）cookie 保存在浏览器，session 保存在客户端
2）cookie 只能存储文本，数据存储类型为 key-value；session 可以存储任意类型的数据
3）cookie 的存储大小有限，默认为 4KB；session 容量没有明确限制。
4）cookie 在集群环境下没有什么问题; session 由于保存在服务器，如果第一次访问如果转发到服务器 1，那么 session 就只保存在服务器 1 上，如果下次请求被转发到服务器 2 上去了，那么用户仍然需要重新登录。
	集群环境下 session 的解决方法：
	1、粘性 session：将同一个用户的请求固定转发到同一个服务器节点上
	2、session 复制：服务器 1 生成一个新的 session，那么将这个 session 同步给其他的集群节点进行复制保存
	3、session 缓存：服务器不再保存 session，而是由 redis 来保存 session，服务器要访问 session 直接从 redis 中获取
```



## TCP 三次握手和四次挥手、SSL 四次握手

```java
1、TCP 三次握手
1）第一次握手：发送方创建一个 TCP 报文，初始化一个随机序列号 seq1，存储到 TCP 头部的序列号位置，然后将 SYN 标志位置 1，发送给接收方。此时处于 SYN_SENT 状态
2）第二次握手：接收方收到后，创建一个 TCP 报文，初始化一个随机序列号 seq2，然后将 seq1 + 1，分别存储到 TCP 头部的序列号和确认号位置，然后将 SYN 和 ACK 标志位置 1，发送给发送方，此时处于 SYN_RECV 状态
3）第三次握手：发送方收到后，创建一个 TCP 报文，将 seq1 + 1 和 seq2 + 1，存储到 TCP 头部的 序列号和确认号位置，然后将 SYN 和 ACK 标志位置 1，此时处于 EMBLISH 建立状态
4）接收方收到后，处于  EMBLISH 建立状态

为什么需要三次握手？
1）只有三次握手才能保证双方的发送和接收能力都正常。
2）同步双方的初始序列号：由于初始序列号作为后面数据传输的基准值，非常重要
3）避免旧的历史连接：如果发送方第一次发送 SYN，由于网络延迟超时了，所以发送方第二次发送 SYN，结果第一个 SYN 先到达接收方，建立连接后，后面的 SYN 再到达接收方，这样的话，接收方并不知道这是一个重发的连接，所以仍然会回应 SYN + ACK，而在第三次握手中，发送方可以判断这是一个历史连接，所以可以回应一个 RST 终止该连接


2、TCP 四次挥手
1）第一次挥手：发送方调用 closed() 发送 FIN + ACK 给接收方，表示自己已经没有数据需要发送了，此时处于 FIN_WAIT1 状态
2）第二次挥手：接收方收到后，会先发送一个 ACK，不过可能由于还有数据没有处理和发送，所以还不会发送 FIN，此时处于 CLOSE_WAIT 状态
3）发送方收到后，处于 FIN_WAIT2 状态
4）第三次挥手：接收方数据处理完毕，调用 closed() 发送 FIN + ACK，此时处于 LAST_ACK 状态
5）第四次挥手：发送方收到后，发送一个 ACK，处于 2MSL 的 TIME_WAIT 状态
6）接收方收到后，进入 CLOSED 状态
7）发送方在 TIME_WAIT 时间内没有收到 FIN，那么进入 CLOSED 状态。

为什么需要 TIME_WAIT？
1）为了保证被动关闭的一方能够正常关闭：如果第四次挥手中 ACK 由于网络原因丢失了，而发送方直接关闭，那么会导致接收方没有收到 ACK 而一直处于 LAST_ACK 状态，如果发送方这时候重用四元组发起 TCP 连接，那么服务器会响应一个 RST 终止连接
2）为了避免旧的数据包出现重用的新的连接上：数据包的有效时间为 MSL，过了这段时间能够让属于本次连接的数据包都消失在网络中，不会留到下次 TCP 连接

为什么 TIME_WAIT 需要 2MSL？
1）等待 2MSL 能够让所有的数据包无效（不过这个原因只需要等待 MSL，不是 2MSL 的真实原因）
2）第四次握手的 ACK 最大存活 MSL 时间，如果这段时间内没有到达接收方，那么接收方会重新发送一个 FIN，而这个 FIN 也是 MSL，它计算这段时间最大的界限为 2MSL

TIME_WAIT 实际上并不能保证让 接收方正常关闭，接收方的关闭实际上存在以下三种状态：
1）接收方处于 LAST_ACK 状态，发送完 FIN 后收到 ACK，进入 CLOSED 状态
2）接收方处于 LAST_ACK 状态，发送完 FIN 后收到 ACK，由于网络延迟原因，发送方的 ACK 在网络中无效，接收方重发的 FIN 也由于网络原因没有到达发送方，那么发送方 TIME_WAIT 时间内没有收到 FIN，进入 CLOSED，等到 FIN 到达 发送方后，发送方会响应一个 RST，接收方收到后进入 CLOSED 状态
3）接收方处于 LAST_ACK 状态，发送完 FIN 后收到 ACK，发送方由于某种原因挂了，那么不会对 FIN 进行任何回应，那么接收方会一直重发，直到重传超时，进入 CLOSED 状态。
因此 TIME_WAIT 实际上只能尽最大努力让接收方正常关闭，而不能进行保证


3、SSL 四次握手
1）第一次握手：客户端初始化一个随机数 seq1，将随机数 和 自己支持的对称加密算法列表发送给服务器
2）第二次握手：服务器收到后，将 seq1 保存起来，然后选定一个加密算法，同时初始化一个随机数 seq2，然后将随机数 和 选定的加密算法、CA 证书发送给客户端
3）第三次握手：客户端收到后，验证 CA 证书，成功后将 seq2 保存起来，初始化一个随机数 seq3，然后将利用选定的对称加密算法 和 三个随机数得到对称加密密钥 secret，然后利用这个密钥加密一段握手信息，同时再利用 CA 证书上的公钥加密 seq3 和 握手信息，发送给服务器
4）第四次握手：服务器收到后，利用自己的私钥解密，然后利用三个随机数和加密算法生成密钥 secret，然后利用 secret 解密加密后的握手信息，解密成功表示自己生成的密钥和客户端的是一致的，然后根据再利用这个密钥加密一段握手信息，直接发送给客户端
5）客户端收到后，利用 secret 进行解密，解密成功表示服务区跟自己生成的密钥是一致的，那么可以进行通信了。
```





## TCP 可靠性实现

```java
1、序列号-确认号机制
2、重传机制（超时重传、快速重传）
    当收到 3 个重复的 ACK 时，那么不需要等待超时计时器超时，直接开始快速重传，因为收到 3 个重复的 ACK 丢包的概率比乱序的概率大：
    我们关注 N，N+1，N+2，N+3，当包的到达顺序如下时，ACK(N+1) 的出现情况：
    乱序：
    N，N+1，N+2，N+3  收到 1 个 ACK(N+1)
    N，N+1，N+3，N+2  收到 1 个 ACK(N+1)
    N，N+2，N+1，N+3  收到 2 个 ACK(N+1)
    N，N+3，N+1，N+2  收到 2 个 ACK(N+1)
    N，N+2，N+3，N+1  收到 3 个 ACK(N+1)
    N，N+3，N+2，N+1  收到 3 个 ACK(N+1)
    丢包：
    N，N+2，N+3 收到 3 个 ACK(N+1)
    N，N+3，N+2 收到 3 个 ACK(N+1)
    
    收到 1 个 和 2 个 重复 ACK 的情况只能是乱序的时候
    而由乱序引发的 3 个重复 ACK 的概率为 2 / 6 = 1 / 3 = 33.3333%
    而由丢包引发的 3 个重复 ACK 的概率为 100%
    即一旦丢包，那么必定会出现 3 个 重复 ACK，因此直接进行重传
    
3、滑动窗口 - 累计确认机制；窗口大小由接收方在 ACK 时候附带告知发送方
4、流量控制 - 发送方根据接收方告知的窗口大小来控制发送的数据量，利用滑动窗口实现
5、拥塞控制 - 发送方不是滑动窗口多大就发送多大的，需要根据网络环境来控制发送速率，这里存在一个拥塞窗口 cwnd
	即 TCP 存在两个窗口 - 滑动窗口和拥塞窗口，滑动窗口是告知发送方可以发送的数据量，拥塞窗口是告知发送方发送滑动窗口内的数据的发送速率
	
拥塞窗口算法：
1）慢启动：指数级增长
	首先 cwnd = 1，即一次只能发送一个数据包
	收到一个 ACK 后，cwnd = 2
	收到两个 ACK 后，cwnd = 4
	收到四个 ACK 后，cwnd = 8
2）拥塞避免：线性增长，慢启动能够很快的提高发送的速率，但是它到达慢启动阈值 ssthresh 就会停止慢启动算法，避免太大的发送速率导致网络拥堵，因此进入到拥塞避免
	比如慢启动阈值 ssthresh = 8，那么此时 cwnd = 8
	那么发送 8 个数据包后，只有收到 8 个 ACK，cwnd + 1 = 9
	发送 9 个数据包后，然后收到 9 个 ACK 后，cwnd + 1 = 10
3）快速重传和快速恢复：在早期的 TCP 拥塞控制版本中，只有慢启动和拥塞避免两种算法，因此一旦出现丢包的超时重传，那么就悲观的认为网络出现了拥堵，那么就会将 cwnd 降为 1，重新开始慢启动算法，这显然会导致在没有网络拥堵的情况下发送速率降低，因此后续的版本出现了快速重传和快速恢复。
	快速重传：当收到 3 个重复的 ACK 后，那么无需等待超时计时器，直接将丢失的包进行发送，然后将 cwnd 减半，同时 ssthresh = cwnd，进入快速恢复算法。
	快速恢复：cwnd = cwnd + 3，往后每收到一个重复的 ACK，那么 cwnd + 1，当收到新的 ACK 后，表示网络已经通畅，那么将 cwnd = ssthresh，结束快速恢复算法，由于 cwnd 到达慢启动阈值，所以开始拥塞避免算法。
	当然，如果没有收到 3 个重复的 ACK，等到超时后，进行超时重传，那么会进入到慢启动算法，因为收到 3 个重复的 ACK 的话，表示网络实际上是通畅的，并不拥堵，同时收到 3 个重复的 ACK 丢包的情况比数据包乱序到达的概率要大得多，所以直接进行重传。
```





## HTTP 状态码

```java
100：用于 Post 两次发送

200：表示客户端请求处理成功，可能有数据返回，存储在响应体中
201：表示客户端请求处理成功，并且存在资源创建，URL 在响应头的 Location 中
202：表示客户端请求尚未处理，也可能后续不会进行处理
204：表示客户端请求处理成功，但没有数据返回
206：用于断点续传，跟 Range 和 Content-Range 配合使用

301：永久重定向，表示资源位置已经永久发生改变，新的 URL 在响应头的 Location 中，浏览器会进行 cache，后续都是访问这个新的 URL
302：临时重定向，表示资源位置暂时发生改变，新的 URL 在响应头的 Location 中，浏览器不会进行 cache，下次访问仍然是访问旧的 URL
303：表示服务器要浏览器重定向到另外一个页面（跟 302 有点像），新的 URL 在响应头的 Location 中，不过重定向的资源并不是原先请求的资源，而是对请求的一些描述，比如使用 Post 上传了一些个人信息，这时候服务器返回一个 303，让浏览器导向一个 ”上传成功“ 的页面。
304：表示资源没有修改，当浏览器发生缓存已经过期时，会发送请求询问服务器，如果服务器资源没有修改，那么响应该状态码告知浏览器可以继续使用缓存

401：Unauthorized，表示客户端未认证，需要先进行认证登录
402：表示需要付费（不过现在没什么作用了）
403：Forbidden，表示客户端已经认证，但是没有权限访问
404：Not Found，表示客户端请求的资源不存在
405：Method Not Allowed HTTP 请求方式不被允许，比如只允许 Post 请求，你却使用 get 请求。

502：网关错误
503：服务器繁忙，现在无法处理请求 或者 服务器不可访问
504：网关超时
```





## 什么是 HTTP？

```javascript
HTTP 是一种请求-响应的协议，它规定了客户端会发送什么样的数据格式给服务器，并且服务器会响应什么样的数据格式给客户端。
HTTP 是一种无状态的，它不会去记录上一次请求的数据，比如上一次请求是哪个用户，因此如果没有 cookie 机制 和 session 机制的话，那么每次用户请求都需要重新登录
    
HTTP 8 种请求方式：
1、get：请求静态资源，请求的参数放在 URL 上，响应的数据在响应体种，幂等
2、post：请求服务器创建资源，非幂等，多次请求会创建多个资源
3、put：请求服务器更新资源，幂等
4、head：类似于 get，不过响应体中不会携带数据，用于获取响应头的信息
5、delete：请求服务器删除指定资源
6、connect：？？？
7、options：？？？
8、trace：？？？
```





## redis 基本数据类型

```
redis 自定义了一种简单的数据结构：redisObject，记录数据类型、编码方式、ptr 指针
数据类型有：string、list、hash、set、zset
string 的编码方式有：int、SDS(embstr、raw，39B 作为界限，因为 embstr 需要连续的内存空间，不能存储太大的数据)
list 的编码格式有：ziplist、linkedlist、quicklist
hash 的编码格式有： ziplist（两个连续的 Entry 存储 filed-value）、dict
set 的编码格式有：intset（类似于 SDS，封装了有序的 int 数组，方便二分查找）、dict
zset 的编码格式有：ziplist（两个连续的 Entry 存储 member 和 score，同时也是保证 score 的有序性）、skiplist + dict


```



## redis 的持久化方式

```java
redis 是一个内存数据库，数据都存储在内存中，如果发生宕机的话会导致数据丢失，所以需要进行持久化。
redis 有两种持久化方式：RDB 和 AOF

1、RDB 文件是一个二进制数据文件，存储的是某一个时间点的数据库快照
RDB 的命令有 save、bgsave
save 的话是由主进程进行 RDB 备份，会停止处理用户命令
bgsave 的话是主进程 fork 一个子进程进行处理，主进程仍然继续处理用户命令，不过新的数据子进程无法感知

bgsave 的过程：
1、执行 bgsave 命令，主进程调用 fork，创建一个子进程2
2、主进程继续执行命令，子进程利用数据库快照，将数据库中的 key-value 数据以二进制的形式备份到新的 RDB 文件中
3、当子进程完成 RDB 备份后，通知父进程，然后退出
4、父进程将新的 RDB 文件替换掉旧的 RDB 文件，完成 RDB 备份。

2、AOF 文件存储的是文本形式的写命令，AOF 持久化包含两部分：AOF 文件 和 AOF buffer
主进程每次执行的 redis 写命令都会存储到 AOF buffer 中，然后按照指定的策略将 AOF buffer 中的数据刷盘到 AOF 文件中，是以日志类型的 append 追加的方式，是顺序 IO，所以效率较高
刷盘策略有以下 3 种：
1）alawys：每执行一条写命令就进行刷盘，这种方式安全性最高，但是频繁的刷盘效率较低，同时也没有很好的使用到 AOF buffer
2）every seconds：每隔 1s 就将 AOF buffer 中的数据刷盘，这样最多只会丢失 1s 内的写命令，是对时间和效率的权衡，是 redis 默认使用的策略
3）no：由操作系统决定刷盘的时机，该策略是不可控的，丢失的数据量也不可控制

而这种频繁的 append 的方式，会导致 AOF 文件变得庞大，因此需要进行 AOF 重写来进行精简，
AOF 重写的前提如下：
	旧的 AOF 文件中有很多的写命令是冗余或者无效的，
	比如 
        rpush list "A"，
        rpush list "B", 
        rpush list "C"
	这三条命令实际上可以合并为一条 rpush list "A" "B" "C"
	比如
		set key "A"
		del key
	设置了某个 key，后面又进行删除。
因此 AOF 重写可以将这个冗余或者无效的命令进行删除，从而达到精简的效果，AOF 重写跟 RDB 备份一样，使用的是数据库的内存快照，并且只会生成插入命令
AOF 重写涉及到两个部分：新的 AOF 文件 和 AOF rewrite buffer
AOF 重写的过程：
1）主进程 fork 一个子进程，
2）主进程继续处理用户命令，子进程利用数据库内存快照进行 AOF 重写
3）主进程会将写命令存储到 AOF buffer 和 AOF rewrite buffer 中
4）当子进程 AOF 重写完成时，通知主进程，然后退出
5）主进程将新的 AOF 文件替换掉旧的 AOF 文件，同时将 AOF rewrite buffer 中的数据写入到新的 AOF 文件中

为什么需要 AOF rewrite buffer？
因为子进程在处理 AOF 重写时，它是无法感知到新的数据的，因此新的 AOF 文件是不会有新的写命令的，因此我们需要将 AOF 重写开始到结束这段过程中的写命令进行存储。

为什么有了 AOF rewrite buffer 还需要将写命令写入到 AOF buffer 中?
因为 AOF 重写可能是一段比较耗费时间的过程，如果这段时间发生宕机，那么在恢复后仍然需要使用 旧的 AOF 文件进行恢复，所以在这段时间仍然需要将写命令写入到 AOF buffer 中然后定时刷盘。

RDB 和 AOF 的区别：
1）优先级：RDB 默认是开启的，AOF 默认是关闭的，如果没有 AOF ，那么会使用 RDB 进行数据恢复，如果有 AOF，那么使用 AOF 进行数据恢复
2）数据恢复的速度：RDB 是二进制数据，恢复的数据快，AOF 是文本的写命令，相当于是将这段时间的写命令执行一遍，效率较低
3）数据丢失量：RDB 数据丢失的是前一次 RDB 文件到宕机这段时间所有的新数据，AOF 根据刷盘策略的不同，默认情况下是丢失 1s 的数据

Linux 的 fork()：
Linux 的 fork() 使用的是写时复制 CopyOnWrite 的方式，子进程会共用父进程的虚拟地址页，在对应的虚拟页没有进行数据修改的时候，那么子进程可以直接使用这些虚拟地址页，而一旦对应的数据页发生修改，那么子进程会在修改前将该页复制出来，然后再进行修改。
进程大部分情况下的虚拟页是不需要修改的，所以子进程可以共用很多的虚拟页，而不需要一开始就全部进行复制，这样节省了很多的内存，不过 Java 的 CopyOnWrite 由于是语言层面的，只能进行备份一份。
```





## redis 快的 5 个原因

```java
1、redis 是 C 语言开发的，比起 Java 这种解释型语言更加贴近操作系统，编译完可以直接运行（Java 是依赖于 JVM 的 java 解释器的，边解释边运行）
2、redis 完全基于内存操作，省去了磁盘 IO 磁盘指针寻道 这种耗时的操作
3、redis 是单进程单线程的，由于不存在磁盘 IO，所以 CPU 的利用率可以说是 100%，设计为单线程可以省去数据共享的加锁操作和线程上下文切换的开销，本来 CPU 全部是内存操作，如果使用多线程，这个线程执行一点，那个线程执行一点，实际上算下来线程上下文切换的开销比单线程的效率要低得多
    （redis 的单线程是指处理用户请求方面的，后台的别的操作比如 RDB 备份、AOF 重写、处理过期 key、定时任务等都是重开一个进程/线程）
4、简洁高效的数据结构：redis 底层自定义了一个数据结构 redisObject，通过不同的数据类型和编码方式，根据数据量来选择适合的数据类型的编码方式，从而提高读写效率。
5、使用 IO 多路复用：redis 的网络 IO 使用的是多路复用 epoll，效率高

redis 的性能设计者说明了不是在 CPU，而是在网络 IO，因为 redis 的这个单线程是同时处理 网络 IO + 用户命令的，但多个 socket 存在事件时，单线程的 网络 IO 处理很大程度上拖慢用户命令的执行。
所以在 redis 6.0 中，它将网络 IO 和 用户命令进行线程隔离， 网络 IO 使用多线程处理，用户命令仍然使用的是单线程。
    
网络 IO 多线程处理：
1）它存在一个线程接收 IO 读写、accept 事件，内部维护了一个线程池，它会将这些事件平均分发给线程池中的线程，包括它自己也会进行处理，不过它一次只能处理一种事件类型，比如此次会统一处理可读事件，处理完后再统一处理可写事件
2）它会自旋等待其他的线程处理完成，然后将读取的命令发送给后台的单线程进行处理
3）等到单线程处理完成后，再获取这些数据，将它分发给每个线程写入
4）主线程会自旋等待所有 socket 写入完成。
```



